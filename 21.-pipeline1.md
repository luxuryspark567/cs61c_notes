# 21. Pipeline1

## Iron Low of Processor Performance

<figure><img src=".gitbook/assets/image (205).png" alt="" width="375"><figcaption></figcaption></figure>

### Instructions per Program

Determined by

* Task
* Algorithm, O(N)
* Programming language
* Compiler
* <mark style="color:yellow;">Instruction Set Architecture (ISA)</mark>

### (Average) Clock Cycles per Instruction (CPI)

<mark style="color:yellow;">How much clocks to finish one instruction</mark>, determined by

* <mark style="color:yellow;">ISA</mark>
* Processor implementation (or micro-architecture)
  * <mark style="color:yellow;">For single-cycle RISC-V design, CPI = 1</mark>
  * <mark style="color:yellow;">Complex instructions (e.g. strcpy), CPI >> 1</mark>
  * <mark style="color:yellow;">Superscalar processors, CPI < 1</mark>

### Time per Cycle (1/Frequency)

Determined by

* Processor micro-architecture (<mark style="color:yellow;">determines critical path through logic gates</mark>)
* Technology (e.g. <mark style="color:yellow;">5nm versus 28nm</mark>): <mark style="color:green;">signal transfer time will be smallerfor 5nm?</mark>
* Power budget (<mark style="color:yellow;">lower voltages reduce transistor speed</mark>): <mark style="color:green;">take capasitor for instance, lower voltage will take more time for it to be charged to certain level</mark>

## Energe in CMOS

> In CMOS circuits, energy dissipation is split between dynamic (capacitor charging/discharging) and static (leakage currents).
>
> 1. <mark style="color:yellow;">**Dynamic Power (70%)**</mark>: Charging and discharging capacitors dominate during switching activity. <mark style="color:yellow;">**Each clock cycle involves**</mark> charging capacitors to a high voltage, consuming significant power.
> 2. <mark style="color:yellow;">**Leakage Power (30%)**</mark>: Even when transistors are off, small currents (leakage) flow due to subthreshold conduction and tunneling effects, especially in modern smaller geometries.
>
> This split reflects typical operating conditions, but the ratio depends on technology node, operating frequency, and usage patterns.
>
> When a logic gate switches states, it charges the output node capacitance to the supply voltage ( V DD ​ ) for <mark style="color:yellow;">a high state</mark> and discharges it to ground for <mark style="color:yellow;">a low state</mark>. <mark style="color:yellow;">This process is essential for propagating logic signals through the circuit.</mark>

<figure><img src=".gitbook/assets/image (209).png" alt=""><figcaption></figcaption></figure>

## Energy Per Task

<figure><img src=".gitbook/assets/image (210).png" alt=""><figcaption></figcaption></figure>

## Energy Trade-off Example

<mark style="color:red;">Does "reduce capacitance" means smaller capasitors, or lesser capasitors?</mark> <mark style="color:yellow;">Should be smaller.</mark>

* "Next-generation" processor
  * Capacitors (Moore's Law): -15%
  * Supply voltage, Vsup: -15%
  * Energy consumption: -(1 - 0.85^2) = -39%
* Significantly improved energy efficiency thanks to
  * <mark style="color:yellow;">Moore's Law</mark>
  * <mark style="color:yellow;">Reduced supply voltage</mark>

## Performance & Power Trends

* The blue show the transistors, as Moore's Law implies
* Around the year of 2005, Frequency and Typical Power get flat, because only by increase the frequency, the heat that generated by the IC is hard to cooling down.
* Around the year of 2005, single thread performance get flat, and number of cores become to increase exponetially.

> Moore's Law:
>
> <mark style="color:yellow;">The complexity for minimum component costs has increased at a rate of roughly a factor of two per year</mark>. Certainly over the short term this rate can be expected to continue, if not to increase. Over the longer term, the rate of increase is a bit more uncertain, although there is no reason to believe it will not remain nearly constant for at least 10 years.

<figure><img src=".gitbook/assets/image (212).png" alt=""><figcaption></figcaption></figure>

## End of Dennard Scaling

* In 1974, Robert Dennard observed that <mark style="color:yellow;">power density(</mark>power consumed per unit area of silicon<mark style="color:yellow;">)</mark> remained constant for a given area of silicon, while the dimension of the transistor shrank. This principle, part of "<mark style="color:yellow;">Dennard scaling</mark>," means <mark style="color:yellow;">smaller transistors consume less power while maintaining performance</mark>, <mark style="color:yellow;">allowing for denser and more efficient circuits. It implies that reducing size does not increase heat per unit area, making it feasible to keep packing more transistors into chips while maintaining energy efficiency and manageable thermal outputs</mark>.
* In recent years, industry has not been able to reduce supply voltage much, as reducing it further <mark style="color:yellow;">would mean increasing "leakage power" where transistor switches don't fully turn off</mark> (more like dimmer switch than on-off switch)&#x20;
* Also, size of transistors and hence capacitance, not shrinking as much as before between transistor generations
  * Need to go to 3D&#x20;
* Power becomes a growing concern - <mark style="color:yellow;">the "power wall"</mark>

{% hint style="info" %}
The "power wall" refers to the challenge in computer processor design where increasing clock speeds results in excessive power consumption and heat generation, limiting performance improvements. This phenomenon arises due to the physical constraints of power dissipation, often breaking the traditional benefits of Dennard scaling, where smaller transistors were expected to consume less power. To overcome this, chip designers shifted focus from single-core performance to multi-core processors and other architectural innovations, emphasizing energy efficiency and parallelism instead of solely increasing clock speeds.
{% endhint %}

## Energy Iron Law

<figure><img src=".gitbook/assets/image (3) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

* Energy efficiency (e.g., <mark style="color:yellow;">instructions/Joule</mark>) is key metric in all computing devices
* For power-constrained systems (e.g., 20MW datacenter), need better energy efficiency to get more performance at same power
* For energy-constrained systems (e.g., W phone), need better energy efficiency to prolong battery life

{% hint style="info" %}
1焦耳(J)=1瓦特×秒(W·s)

1度(1kw·h)=3.6×10^6焦耳(J)

瓦特是国际单位制的功率单位。瓦特的定义是1焦耳/秒（1J/s），即每秒转换、使用或耗散的（以焦耳为量度的）能量的速率。在电学单位制中，是伏特乘安培乘功率因数（1V·A，简称1伏安）。

热量（Joule）的公制单位，简称“焦”，是为了纪念英国著名物理学家詹姆斯·普雷斯科特·焦耳而创立的。
{% endhint %}

## Pipeline

* Pipelining <mark style="color:red;">doesn't help latency of single task</mark>, <mark style="color:yellow;">it helps</mark> <mark style="color:yellow;"></mark><mark style="color:yellow;">**throughput**</mark> <mark style="color:yellow;"></mark><mark style="color:yellow;">of entire workload</mark>
* Multiple tasks operating simultaneously using different resources
* <mark style="color:yellow;">Potential speedup = Number of pipe stages</mark>
* <mark style="color:yellow;">Time to</mark> <mark style="color:yellow;"></mark><mark style="color:yellow;">**"fill" pipeline**</mark> <mark style="color:yellow;"></mark><mark style="color:yellow;">and time to</mark> <mark style="color:yellow;"></mark><mark style="color:yellow;">**"drain" it**</mark> <mark style="color:yellow;"></mark><mark style="color:yellow;">reduces speedup:</mark>&#x20;
  * 2.3X v. 4X in this example
* Pipeline rate (clock rate) <mark style="color:yellow;">limited by slowest pipeline stage</mark>&#x20;
* <mark style="color:yellow;">Unbalanced lengths of pipe stages reduce speedup;</mark>

<figure><img src=".gitbook/assets/image (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt="" width="375"><figcaption></figcaption></figure>



## Conclusion

* Instruction timing
  * Set by instruction complexity, architecture, technology
  * Pipelining increases clock frequency, "instructions per second"
    * But does not reduce time to complete instruction
* Performance measures
  * Different measures depending on objective
    * Response time
    * Jobs / Second
    * Energy per task
