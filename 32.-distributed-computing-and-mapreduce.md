# 32. Distributed Computing and MapReduce

* Concurrency is hard.
  * Separate programs usually don't share memory.●Sharing state between different programs is hard.
  * Hard to use locks.
*   Handling failure is hard.

    * Single program: If a thread crashes, the whole program crashes.●Distributed computing: If one program crashes, the others keep going.
    * Can create "zombie processes" that keep running after everyone else is finished.\
      Consumes resources until we restart the system.


* Communication is hard.
* Programs coordinate by sending messages between each other.●Messages can take time to transmit (e.g. over the Internet).
* It takes time to start communication, transmit bytes of data, access memory, etc.
* What if Program A sends a message to Program B...but Program B isn't expecting to receive a message?



* Goal: Split problem into independent sub-tasks, and minimize communication between programs.

## Manager-Worker Framework

Manager pseudocode:

1. Setup.
2. While there's still work to do:
   1. Wait for a worker to request more work.
   2. Find the next task to do.
   3. Tell that worker what task to do.
3. Repeat once per worker:
   1. Wait for a worker to request more work.●Tell that worker we're all done.
4. Teardown.

Worker pseudocode:

1. Setup.
2. done=False.
3. While done==False:
   1. Send manager a request for work.
   2. Receive message from manager.
   3. If message is work: Do the work.
   4. If message is "all done": Set done=True.
4. Teardown.
