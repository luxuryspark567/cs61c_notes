# 29. OpenMP, Sharing lssues

## Why So Many Parallel Programming Languages?

* ﻿﻿Why "intrinsics"?
  * ﻿﻿TO Intel: fix your compiler, thanks...
* ﻿﻿It's happening ... but
  * ﻿﻿SIMD features are continually added to compilers (Intel, gcc)
  * Intense area of research
  * ﻿﻿Research progress:
    * ﻿﻿<mark style="color:yellow;">20+ years to translate C into good (fast) assembly</mark>
    * ﻿﻿How long to <mark style="color:yellow;">translate C into good (fast) parallel code</mark>?
      * <mark style="color:red;">General problem is very hard to solve</mark>
      * Present state: <mark style="color:yellow;">specialized solutions for specific cases</mark>

## Parallel Programming Languages

* ﻿﻿Number of choices is indication of
  * ﻿﻿No universal solution, needs are very <mark style="color:red;">problem specific</mark>
    * ﻿﻿Scientific computing/machine learning (<mark style="color:yellow;">matrix multiply</mark>)
    * ﻿﻿Webserver: handle many <mark style="color:yellow;">unrelated requests simultaneously</mark>,
    * ﻿﻿Input / output: it's all happening simultaneously!
* ﻿﻿Specialized languages for different tasks
  * ﻿﻿Some are easier to use (for some problems)
  * ﻿﻿None is particularly "easy" to use

## <mark style="color:red;">OpenMP</mark>

<figure><img src=".gitbook/assets/image (2) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

* <mark style="color:yellow;">C extension</mark>: no new language to learn
* ﻿﻿<mark style="color:yellow;">Multi-threaded,</mark> <mark style="color:red;">shared-memory parallelism</mark>
  * ﻿﻿Compiler Directives, <mark style="color:yellow;">#pragma</mark>
  * ﻿﻿Runtime Library Routines, <mark style="color:yellow;">#include \<omp. h></mark>
* ﻿﻿<mark style="color:yellow;">#pragma</mark>
  * ﻿﻿<mark style="color:yellow;">Ignored by compilers unaware of OpenMP</mark>
  * ﻿﻿<mark style="color:yellow;">Same source for multiple architectures</mark>
    * ﻿﻿E.g., same program for 1 & 16 cores
* ﻿﻿<mark style="color:red;">**Only**</mark> <mark style="color:yellow;">works with</mark> <mark style="color:red;">shared memory</mark>

{% hint style="info" %}
OpenMP is designed for <mark style="color:red;">**shared-memory architectures**</mark> because <mark style="color:yellow;">it relies on threads running in the same address space to share data</mark>. In a shared memory model, all threads have direct access to the same memory, enabling efficient communication and synchronization between them using OpenMP's constructs like `#pragma omp parallel`.

In contrast, <mark style="color:red;">**distributed-memory systems**</mark> (e.g., clusters) require explicit data transfer between memory spaces (e.g., using MPI). OpenMP does not natively support this, as it assumes the memory is shared and accessible by all threads without explicit communication.
{% endhint %}

## OpenMP Programming Model

<figure><img src=".gitbook/assets/image (282).png" alt="" width="563"><figcaption></figcaption></figure>

* OpenMP programs begin as single process (main thread)
  * Sequential execution
* When parallel region is encountered
  * Master thread <mark style="color:yellow;">"forks"</mark> into team of parallel threads
  * <mark style="color:yellow;">Executed simultaneously</mark>
  * At end of parallel region, parallel threads <mark style="color:yellow;">"join"</mark>, leaving only master thread
* Process repeats for each parallel region
  * Amdahl's Law?

## What Kind of Threads?

* ﻿﻿OpenMP threads are <mark style="color:red;">operating system (software) threads</mark>
* ﻿﻿<mark style="color:red;">OS will multiplex requested OpenMP threads onto available hardware threads</mark>
* ﻿﻿Hopefully each gets a real hardware thread to run on, so no OS-level time-multiplexing
* ﻿﻿But other tasks on machine compete for hardware threads!
* ﻿﻿Be "careful" (?) when timing results for Projects!
  * ﻿﻿5АМ?
  * ﻿﻿Job queue?

## Computing PI

<figure><img src=".gitbook/assets/image (6) (1) (1) (1) (1) (1) (1).png" alt="" width="563"><figcaption></figcaption></figure>

<figure><img src=".gitbook/assets/image (7) (1) (1) (1) (1) (1) (1).png" alt="" width="563"><figcaption></figcaption></figure>

<figure><img src=".gitbook/assets/image (8) (1) (1) (1) (1).png" alt="" width="563"><figcaption></figcaption></figure>

如果for循环中有一个**公用变量**（即多个线程共享的变量），<mark style="color:red;">可能会导致竞争条件（Race Condition）</mark>，多个线程同时访问和修改同一个共享变量，导致程序行为不确定或结果错误。解决方式为用临时变量记录每次的结果，最后合并为一个变量。



<figure><img src=".gitbook/assets/image (9) (1) (1) (1).png" alt="" width="563"><figcaption></figcaption></figure>



### Synchronization

* Problem:
  * ﻿﻿<mark style="color:yellow;">Limit access to shared resource to 1 actor at a time</mark>
  * ﻿﻿E.g. only 1 person permitted to edit a file at a time
    * ﻿﻿otherwise changes by several people get all mixed up

## <mark style="color:red;">Locks</mark>

* Computers use locks to control access to shared resources
  * Serves purpose of microphone in example
  * Also referred to as "<mark style="color:red;">semaphore</mark>"
* Usually implemented with a variable
  * int lock;
    * 0 for unlock
    * 1 for locked

## Lock Synchronization

<mark style="color:red;">Software level(even at the assembly level) lock cannot solve racing problem</mark>, the codes below still racing while trying to get the lock.

<figure><img src=".gitbook/assets/image (38).png" alt="" width="563"><figcaption></figcaption></figure>

## Conclusion

* OpenMP as simple parallel extension to C
  * Threads level programming with parallel for pragma
  * Similar to C: Small so easy to learn, but not very high level and it's easy to get into trouble
* Race condition - result of program depends on chance
  * Need assembly-level instructions to help with lock synchronization
