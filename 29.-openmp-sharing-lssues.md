# 29. OpenMP, Sharing lssues

## Why So Many Parallel Programming Languages?

* ﻿﻿Why "intrinsics"?
  * ﻿﻿TO Intel: fix your compiler, thanks...
* ﻿﻿It's happening ... but
  * ﻿﻿SIMD features are continually added to compilers (Intel, gcc)
  * Intense area of research
  * ﻿﻿Research progress:
    * ﻿﻿20+ years to translate C into good （fast！） assembly
    * ﻿﻿How long to translate C into good (fast!) parallel code?
      * General problem is very hard to solve
      * Present state: specialized solutions for specific cases
      * Your opportunity to become famous!

## Parallel Programming Languages

* ﻿﻿Number of choices is indication of
  * ﻿﻿No universal solution
    * ﻿﻿Needs are very problem specific
  * ﻿﻿E.g.,
    * ﻿﻿Scientific computing/machine learning (matrix multiply)
    * ﻿﻿Webserver: handle many unrelated requests simultaneously,
    * ﻿﻿Input / output: it's all happening simultaneously!
* ﻿﻿Specialized languages for different tasks
  * ﻿﻿Some are easier to use (for some problems)
  * ﻿﻿None is particularly "easy" to use
* ﻿﻿61C
  * ﻿﻿Parallel language examples for high-performance computing
  * ﻿﻿OpenMP

## OpenMP

<figure><img src=".gitbook/assets/image (2).png" alt=""><figcaption></figcaption></figure>

* C extension: no new language to learn
* ﻿﻿Multi-threaded, shared-memory parallelism
  * ﻿﻿Compiler Directives, #pragma
  * ﻿﻿Runtime Library Routines, #include \<omp. h>
* ﻿﻿#pragma
  * ﻿﻿Ignored by compilers unaware of OpenMP
  * ﻿﻿Same source for multiple architectures
    * ﻿﻿E.g., same program for 1 & 16 cores
* ﻿﻿Only works with shared memory

## OpenMP Programming Model

<figure><img src=".gitbook/assets/image (282).png" alt=""><figcaption></figcaption></figure>

* OpenMP programs begin as single process (main thread)
  * Sequential execution
* When parallel region is encountered
  * Master thread "forks" into team of parallel threads
  * Executed simultaneously
  * At end of parallel region, parallel threads "join", leaving only master thread
* Process repeats for each parallel region
  * Amdahl's Law?

## What Kind of Threads?

* ﻿﻿OpenMP threads are operating system (software) threads
* ﻿﻿OS will multiplex requested OpenMP threads onto available hardware threads
* ﻿﻿Hopefully each gets a real hardware thread to run on, so no OS-level time-multiplexing
* ﻿﻿But other tasks on machine compete for hardware threads!
* ﻿﻿Be "careful" (?) when timing results for Projects!
  * ﻿﻿5АМ?
  * ﻿﻿Job queue?

## Computing PI

<figure><img src=".gitbook/assets/image (6).png" alt="" width="375"><figcaption></figcaption></figure>

<figure><img src=".gitbook/assets/image (7).png" alt="" width="375"><figcaption></figcaption></figure>

<figure><img src=".gitbook/assets/image (8).png" alt="" width="375"><figcaption></figcaption></figure>

<figure><img src=".gitbook/assets/image (9).png" alt="" width="375"><figcaption></figcaption></figure>

## Can we Parallelize Computing sum?

<figure><img src=".gitbook/assets/image (11).png" alt="" width="563"><figcaption></figcaption></figure>

<figure><img src=".gitbook/assets/image (12).png" alt="" width="563"><figcaption></figcaption></figure>



Synchronization

* Problem:
  * ﻿﻿Limit access to shared resource to 1 actor at a time
  * ﻿﻿E.g. only 1 person permitted to edit a file at a time
    * ﻿﻿otherwise changes by several people get all mixed up

<figure><img src=".gitbook/assets/image (14).png" alt=""><figcaption></figcaption></figure>

<mark style="color:yellow;">Still racing while trying to get the lock.</mark>

<figure><img src=".gitbook/assets/image (16).png" alt=""><figcaption></figcaption></figure>

<figure><img src=".gitbook/assets/image (17).png" alt=""><figcaption></figcaption></figure>















