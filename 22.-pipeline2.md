# 22. Pipeline2

## Five Stages

<figure><img src=".gitbook/assets/image (218).png" alt="" width="563"><figcaption></figcaption></figure>

## Single-cycle CPU & pipelined CPU

* Pipelined CPU uses <mark style="color:red;">one clock for all stages</mark>, clock cycle time is limited by the slower statges.
* <mark style="color:red;">Shade is???</mark>
  * Shades means the priority if two blocks happens in the same clock: if WB and ID are in the same clock period, should **write-then-read**.

## Throughput

<figure><img src=".gitbook/assets/image (220).png" alt="" width="563"><figcaption></figcaption></figure>

Recaculate PC + 4 to avoid sending both PC and PC + 4 down pipeline.

<figure><img src=".gitbook/assets/image (221).png" alt="" width="563"><figcaption></figcaption></figure>

## Control is also pipelined

* Control signals are derived from the instruction. Like in the one-cycle CPU, <mark style="color:red;">contral is usually computed in ID stage</mark>
* Control informantion for later stages  is <mark style="color:red;">stored in pipeline registers</mark>

<figure><img src=".gitbook/assets/image (222).png" alt="" width="563"><figcaption></figcaption></figure>

## Three Types of Pipeline Hazards&#x20;

<mark style="color:yellow;">A hazard is a situation in which a planned instruction cannot execute in the "proper" clock cycle</mark>.&#x20;

* <mark style="color:yellow;">Structural hazard</mark>:
  * Hardware does not support <mark style="color:red;">access across multiple instructions</mark> in the same cycle.&#x20;
  * PC每个周期跳转一次，这里的hazard主要是指code access & data access，以及data的read & write。
* <mark style="color:yellow;">Data hazard</mark>:&#x20;
  * Instructions have <mark style="color:yellow;">data dependency</mark>.
  * Need to wait for previous instruction to complete its data read/write.
* <mark style="color:yellow;">Control hazard</mark>:
  * Flow of execution depends on previous instruction.

## Structural Hazard

* Solution 1 (inefficient):
  * Instructions take turns using the resource.
  * Some instructions stall while the resource is busy.
* Solution 2: Add more hardware! hold all these limes?
  * Can always solve structural hazards by adding more HW.&#x20;
  * <mark style="color:yellow;">In our current CPU, structural hazards are not an issue</mark>.
    * <mark style="color:red;">Seperate IMEM and DMEM</mark> <mark style="color:yellow;">avoids structure hazard, and RV32I's required seperate IMEM and DMEM works.</mark>&#x20;
      * <mark style="color:red;">Different caches, but the actual memory is the same,</mark> <mark style="color:yellow;">then cache access memory might still trigger conflicts? But cache fetches is not so time critical?</mark>
      * <mark style="color:red;">IMEM and DMEM is refers to cache memory</mark> <mark style="color:yellow;">in the current design?</mark>
    * <mark style="color:yellow;">RegFile have</mark> <mark style="color:red;">seperate ports for rs1, rs2 and rsW</mark><mark style="color:yellow;">, and they work simutaneously.</mark>

<figure><img src=".gitbook/assets/image (223).png" alt="" width="563"><figcaption></figcaption></figure>

## Data Hazards

* Data hazard:&#x20;
  * <mark style="color:yellow;">Instructions have</mark> <mark style="color:red;">data dependency</mark><mark style="color:yellow;">.</mark>
  * <mark style="color:yellow;">Need to</mark> <mark style="color:red;">wait for previous instruction to complete</mark> <mark style="color:yellow;">its data read/write.</mark>
* Three cases to consider:&#x20;
  * Register access
  * ALU Result
  * Load data hazard

### Register Access

* If the <mark style="color:yellow;">same register is written and read in one cycle</mark>:
  * <mark style="color:red;">WB must write value before ID read new value.</mark>
  * <mark style="color:yellow;">Not structural hazard</mark>, seperate ports allow simultaneous R/W.
* Solution: Regfile HW should <mark style="color:yellow;">**write-then-read**</mark> in same cycle
  * <mark style="color:yellow;">**Exploits high speed**</mark> of RegFile(100ps + 100ps) (If not fast enough, it is not possible to do this)
  * <mark style="color:red;">Indicated by shading in diagram (Here shows the meaning of shades in RegFile WB and ID)</mark>
  * <mark style="color:yellow;">Might not always be possible to write-then-read in same cycle, e.g.,</mark> <mark style="color:yellow;"></mark><mark style="color:yellow;">**in high-frequency designs**</mark><mark style="color:yellow;">.</mark> <mark style="color:red;">Why???</mark>
    * 高频设计留给写入和读取的时间都很短，如果要求write-then-read，时序可能会无法满足高频设计的要求，这时候就要通过其他的方式处理了，例如插入气泡、调整执行指令的顺序等。

<figure><img src=".gitbook/assets/image (229).png" alt="" width="375"><figcaption></figcaption></figure>

### ALU Result&#x20;

* Problem:
  * Instruction <mark style="color:yellow;">depends on WB's RegFile write</mark> from previous instruction.

<figure><img src=".gitbook/assets/image (232).png" alt="" width="563"><figcaption></figcaption></figure>

* Solution1: <mark style="color:yellow;">**Stalling**</mark>
  * <mark style="color:red;">"Bubble" to effectively nop</mark>:
    * ﻿﻿Affected pipeline stages do nothing during clock cycles.
    * ﻿﻿Stall all stages by preventing PC, IF/ID pipeline register from writing (more in textbook).
  * <mark style="color:yellow;">Stalls reduce performance</mark>.
    * Compiler could rearrange code/insert nops to avoid hazards (and therefore stalls), but this requires knowledge of the pipeline structure.

<figure><img src=".gitbook/assets/image (231).png" alt="" width="563"><figcaption></figcaption></figure>

* Solution2: <mark style="color:yellow;">**Forwarding**</mark>
  * <mark style="color:yellow;">Forwarding, aka bypassing,</mark> <mark style="color:yellow;"></mark><mark style="color:yellow;">**uses the result when it is computed**</mark>.（在计算结果出来之后立即通过硬件电路将数据向前传递，不需要等待写回到寄存器再读取）
    * ﻿﻿Don't wait for value to be stored into RegFile.
    * ﻿﻿Instead, grab operand from the pipeline stage.
  * Implementation:
    * Make <mark style="color:red;">extra connections in the datapath</mark>.
    * Also <mark style="color:red;">add forwarding control logic</mark>.
    * 注意，这里的计算的Fowarding是直接把ALU的输出，在下一个clock写入到ALU的输入。

<figure><img src=".gitbook/assets/image (233).png" alt="" width="563"><figcaption></figcaption></figure>

## Forward Control Logic

<figure><img src=".gitbook/assets/image (234).png" alt=""><figcaption></figcaption></figure>

### Load data hazard

* The instruction slot after a load is called <mark style="color:red;">the load delay slot</mark>.
* If this instruction uses the result of load:
  * The hardware must <mark style="color:yellow;">stall for one cycle</mark> (<mark style="color:red;">plus forwarding</mark>).
  * This results in performance loss!
  * 注意，这里的Memory读取的结果，在下一个clock写入到ALU的输入。
  * <mark style="color:red;">这里为什么一定要有一个nop指令？</mark>
    * 因为这里和前面的计算的Fowarding不一样，还需要读取DMEM的内容才能进行Fowarding，所以要增加一个NOP等待DMEM读取完成，然后Forwarding硬件将计算结果推送到ALU的输入端。

<figure><img src=".gitbook/assets/image (237).png" alt=""><figcaption></figcaption></figure>

Solutjon: Code Scheduling

* Idea (Reorder): <mark style="color:red;">Fix this hazard at the code compilation state</mark>

<figure><img src=".gitbook/assets/image (238).png" alt=""><figcaption></figcaption></figure>

## Control Hazard

主要发生在条件判断语句中。

这也是为什么在代码优化的时候，特别是Linux源码中，有关键字告诉编译器，哪一个条件是高概率的，哪一个条件是低概率的。而且在一般代码的编写的时候，也要注意把高概率的条件放到最前面，这样也可以提高代码执行的效率。<mark style="color:red;">一旦预测出错，流水线将执行flushing操作。</mark>

```
if (likely(condition)) {
    // 高概率路径
} else {
    // 低概率路径
}
```

Control hazards occur when the instruction fetched may not be the one needed.

<figure><img src=".gitbook/assets/image (239).png" alt=""><figcaption></figcaption></figure>

## Branch Prediction

* Every taken branch in the simple RV32I pipeline costs 3 clock cycles.
* We can improve the CPU performance on average through branch prediction.
  * Early in the pipline, guess which way braches will go
  * <mark style="color:red;">Flush pipeline if branch prediction was incorrect.</mark>
* Naive Prediction: Don't take branch. The simple RV32I pipeline effectively always "predicts" that braches are not taken. （也就是不做特殊处理，直接认为if条件的下一个指令就是正确的prediction）

## Pipelining and ISA Design

* The RISC-V ISA is designed for pipelining:
  * All instruction are 32 bits wide.
    * Easy to fetch and decode, each in one clock cycle.
    * Contrast with <mark style="color:red;">CISC: 1- to 15-byte-wide instructions</mark>.
  * A small set of standard instruction formats
    * Can decode/read registers in one stage.
  * Load/store addressing conceptually:
    * Calculate address in 3rd stage (with ALU)
    * Access memory in 4th stage
  * Memory operands are all aligned
    * Memory access takes only one cycle.

Further Increasing Processor Performance

* Increase clock rate.
  * Limited by technology and power dissipation.
* Increase pipeline depth.
  * "Overlap" instructions execution through deeper pipeline, e.g., 10 or 15 stages.
    * Less work per stage -> shorter clock cycle/lower power
    * But more potential for all three types of hazards
* Design a "superscalar" processor.
  * Multiple-issue: Start multiple instructions per clock cycle.
  * Dynamic "out-of-order": Reorder instructions dynamically in HW to reduce impact of hazards.

## CPI Measure in Practice

* Measure CPI on various benchmarks:
  * Known benchmark programs from a variety of application domains:
    * Data compression, code compilation, video recording, network simulation, etc.

<figure><img src=".gitbook/assets/image (240).png" alt="" width="563"><figcaption></figcaption></figure>
