# 6. Float

## Fixed Binary Point

* Example 6-bit representation, range is 0 to 3.9375 (almost 4).

$$
10.1010 = 1*2^{1} + 1*2^{-1} + 1*2^{-3} = 2.62510
$$

* Support elementary math.

## Floating Point (Single Precision)

The IEEE 754 standard defines a binary representation for floating point values using three fields.&#x20;

<figure><img src=".gitbook/assets/image (4).png" alt="" width="375"><figcaption></figcaption></figure>

<figure><img src=".gitbook/assets/image (7).png" alt="" width="563"><figcaption></figcaption></figure>

<figure><img src=".gitbook/assets/image (3).png" alt="" width="375"><figcaption></figcaption></figure>

* The <mark style="color:orange;">Sign</mark> determines the sign of the number (0 for positive, 1 for negative).&#x20;
* The <mark style="color:blue;">Exponent</mark> is <mark style="color:red;">in biased notation</mark>. For instance, <mark style="color:red;">the bias is -127</mark> which comes from -(2^(8−1) − 1) for single-precision floating point numbers.&#x20;
* The <mark style="color:yellow;">Significand</mark> or `mantissa` is akin to unsigned integers, but used to store a fraction instead of an integer. <mark style="color:red;">0 < Significand <1</mark>.

The below table shows the bit breakdown for the single precision (32-bit) representation. The leftmost bit is the MSB and the rightmost bit is the LSB.

[https://www.h-schmidt.net/FloatConverter/IEEE754.html](https://www.h-schmidt.net/FloatConverter/IEEE754.html)

### **For normalized floats**:（Exp 1～254）

$$
Value = -1^{Sign} * 2^{Exp + Bias} * 1.Significant_{2}
$$

* Positive Max: <mark style="color:orange;">1</mark> \* <mark style="color:yellow;">(2-2^(-23))</mark> \* <mark style="color:blue;">2^127</mark>  = 2^128 - 2^104 = 3.4\*10^38;&#x20;
  * <mark style="color:orange;">Sign</mark>: 1;&#x20;
  * 1.<mark style="color:yellow;">Significant</mark>:&#x20;
    * 2^0 + <mark style="color:yellow;">2^(-1) + 2^(-2)... + 2^(-23)</mark> = 2 - 2^(-23); （2^(-22) = 2^(-23) + 2^(-23)）
  * 2^(<mark style="color:blue;">Exponent</mark> - 127):&#x20;
    * 2^(254 - 127) = <mark style="color:blue;">2^127</mark>
* Positive Min: 1 \* 2^(-126) \* 1 = <mark style="color:red;">2^(-126)</mark> = 1.175\*10^(-38)

### **For denormalized floats**:

<mark style="color:red;">No (implied) leading 1, implicit exponent = -126.</mark>

$$
Value = -1^{Sign} * 2^{-126} * 0.Significant_{2}
$$

* Positive Max: <mark style="color:orange;">1</mark> \* <mark style="color:yellow;">(1 - 2^(-23))</mark> \* <mark style="color:blue;">2^(-126)</mark> = 2^(-126) - 2^(-149) = 1.175\*10^(-38) (very close to 2^(-126))
* Positive Min: <mark style="color:orange;">1</mark> \* <mark style="color:blue;">2^(-126)</mark> \* <mark style="color:yellow;">2^(-23)</mark> = 2^(-149) = 1.4\*10^(-45)

{% hint style="info" %}
Why is there a denormalized float representation?

1. Normalized representation has smallest value <mark style="color:red;">2^(-126)</mark> (the minimum exponent is 1), which is a huge gap from 0.&#x20;
2. Even if the mininum exponent could go to 0, the smallest positive number is <mark style="color:red;">2^(-127)</mark>, which is still a huge gap compaired with <mark style="color:red;">2^(-149)</mark>.
3. The smallest <mark style="color:red;">exponent (−126) ensures a smooth transition</mark> between the smallest normalized value ( 1.0 × 2^(−126) ) and the largest denormalized value. Denormalized numbers are used to represent values closer to zero, maintaining gradual underflow.
{% endhint %}

<figure><img src=".gitbook/assets/image (2) (1).png" alt="" width="563"><figcaption></figcaption></figure>

Note that in the above table, our exponent has values from 0 to 255. When translating between binary and decimal floating point values, we must remember that there is a bias for the exponent.

Once exponent surpasses the length of the significand, the number's precision begins to drop.

{% hint style="info" %}
Take <mark style="color:red;">Significand</mark> as the markings on a ruler, and Exponend (actually is 2^(Exp + Bias)) as minimal gap between markings.&#x20;

When Significand changing from the minimal value to the maximal value repeatedly for each Exponent value: <mark style="color:red;">Once runs to the ruler's end, the ruler restarts and</mark> <mark style="color:red;"></mark><mark style="color:red;">**the gap gets doubled everytime**</mark><mark style="color:red;">, When comes to the ruler's end, means that Exponent need to increase by 1;</mark>

The ruler has total about 2^Significand markings.&#x20;
{% endhint %}

### Decimal to Floating Point

* Example 1: Convert 365.625 to float32 format
  * Convert the number before and after the decimal point to binary <mark style="color:red;">separately</mark>.
    * 365.625 => 365 = 101101101, 0.625 = 0.101 => 101101101.101
  * Move the decimal and account for the exponent.
    * 101101101.101 -> 1.<mark style="color:yellow;">01101101101</mark>\*2^<mark style="color:blue;">8</mark>
  * Allocate bits into the appropriate fields.
    * Sign: 0
    * Exp: (8 + 127) = 135 (<mark style="color:blue;">10000111b</mark>)
    * <mark style="color:yellow;">Mantissa: 01101101101</mark><mark style="color:green;">000000000000</mark>
  * Concatenate bits into bitstring.
    * <mark style="color:orange;">0</mark><mark style="color:blue;">10000111</mark><mark style="color:yellow;">01101101101</mark><mark style="color:green;">000000000000</mark>
* Example 2: Convert 2^(-128) to float32 format
  * <mark style="color:red;">2^(-128) is smaller than 2^(-126),</mark> <mark style="color:orange;">choose denormalized representation</mark>
    * 2^(-128) = 2^(-126) \* 2^(-2)
  * Allocate bits into the appropriate fields.
    * Sign: 0
    * Exp: 0
    * <mark style="color:yellow;">Mantissa: 01000000000</mark><mark style="color:green;">000000000000</mark>
  * Concatenate bits into bitstring.
    * 00000000001000000000000000000000

<figure><img src=".gitbook/assets/image (9) (1) (1) (1) (1) (1) (1) (1).png" alt="" width="563"><figcaption></figcaption></figure>

## Double Precision

Double precision identical, except exponent bias of <mark style="color:red;">-1023 (half, quad similar)</mark>

## Double Precision Fl. Pt. Representation

<figure><img src=".gitbook/assets/image (71).png" alt="" width="563"><figcaption></figcaption></figure>

## Double Precision (vs. Single Precision)&#x20;

* C variable declared as <mark style="color:red;">double</mark>&#x20;
* Represent numbers almost as small as <mark style="color:red;">2.0 x 10^(-308)</mark> to almost as large as <mark style="color:red;">2.0 x 10^308</mark>&#x20;
* But primary advantage is <mark style="color:red;">greater accuracy</mark> due to larger significand

## Precision and Accuracy

* <mark style="color:red;">Precision</mark> is a count of <mark style="color:red;">the number bits</mark> in used to represent a value.&#x20;
* <mark style="color:red;">Accuracy</mark> is the <mark style="color:red;">difference between</mark> the actual value of a # and its computer representation.&#x20;
* <mark style="color:red;">High precision permits high accuracy but doesn’t guarantee it.</mark>&#x20;
  * It is possible to have high precision but low accuracy.
  * Example: float pi = 3.14;&#x20;
    * pi will be represented using all 24 bits of the significant (highly precise), but is only an approximation (not accurate).

### Scientific Notation (in Decimal)

<figure><img src=".gitbook/assets/image (16) (1) (1) (1) (1) (1).png" alt="" width="563"><figcaption></figcaption></figure>

* Normalized form: no leadings 0s (exactly one digit to left of decimal point)&#x20;
* Alternatives to representing 1/1,000,000,000&#x20;
  * Normalized: 1.0 x 10-9&#x20;
  * Not normalized: 0.1 x 10-8, 10.0 x 10-10

### Scientific Notation (in Binary)

<mark style="color:red;">The binary point is not fixed</mark>.

<figure><img src=".gitbook/assets/image (17) (1) (1) (1) (1).png" alt="" width="563"><figcaption></figcaption></figure>

### Floating Point Representation
