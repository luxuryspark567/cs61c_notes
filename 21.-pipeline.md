# 21. Pipeline

## Iron Low of Processor Performance

<figure><img src=".gitbook/assets/image (205).png" alt=""><figcaption></figcaption></figure>

CPI, Cycles Per Instruction

Process time of a program = instructions of the program \* CPI \* Period of clock

### Instructions per Program

Determined by

* Task
* Algorithm, O(N)
* Programming language
* Compiler
* <mark style="color:yellow;">Instruction Set Architecture (ISA)</mark>

### (Average) Clock Cycles per Instruction (CPI)

Determined by

* <mark style="color:yellow;">ISA</mark>
* Processor implementation (or micro-architecture)
  * E.g. <mark style="color:yellow;">for single-cycle RISC-V design, CPI = 1</mark>
  * <mark style="color:yellow;">Complex instructions (e.g. strcpy), CPI >> 1</mark>
  * <mark style="color:yellow;">Superscalar processors, CPI < 1</mark>

### Time per Cycle (1/Frequency)

Determined by

* Processor micro-architecture (<mark style="color:yellow;">determines critical path through logic gates</mark>)
* Technology (e.g. <mark style="color:yellow;">5nm versus 28nm</mark>): <mark style="color:green;">signal transfer time will be smallerfor 5nm?</mark>
* Power budget (<mark style="color:yellow;">lower voltages reduce transistor speed</mark>): <mark style="color:green;">take capasitor for instance, lower voltage will take more time for it to be charged to certain level</mark>

## Energe in CMOS

While charging the capasitor, 70% energy will go to the capasitor CV^2, and 30% energy will be spent as leakage.

> In CMOS circuits, energy dissipation is split between dynamic (capacitor charging/discharging) and static (leakage currents).
>
> 1. **Dynamic Power (70%)**: Charging and discharging capacitors dominate during switching activity. <mark style="color:yellow;">**Each clock cycle involves**</mark> charging capacitors to a high voltage, consuming significant power.
> 2. **Leakage Power (30%)**: Even when transistors are off, small currents (leakage) flow due to subthreshold conduction and tunneling effects, especially in modern smaller geometries.
>
> This split reflects typical operating conditions, but the ratio depends on technology node, operating frequency, and usage patterns.
>
> When a logic gate switches states, it charges the output node capacitance to the supply voltage ( V DD ​ ) for <mark style="color:yellow;">a high state</mark> and discharges it to ground for <mark style="color:yellow;">a low state</mark>. <mark style="color:yellow;">This process is essential for propagating logic signals through the circuit.</mark>

<figure><img src=".gitbook/assets/image (209).png" alt=""><figcaption></figcaption></figure>

## Energy Per Task

<figure><img src=".gitbook/assets/image (210).png" alt=""><figcaption></figcaption></figure>

## Energy Trade-off Example

<mark style="color:red;">Does "reduce capacitance" means smaller capasitors, or lessor capasitors?</mark>

* "Next-generation" processor
  * Capacitors (Moore's Law): -15%
  * Supply voltage, Vsup: -15%
  * Energy consumption: -(1 - 0.85^2) = -39%
* Significantly improved energy efficiency thanks to
  * <mark style="color:yellow;">Moore's Law</mark>
  * <mark style="color:yellow;">Reduced supply voltage</mark>

## Performance & Power Trends

* The blue show the transistors, as Moore's Law implies
* Around the year of 2005, Frequency and Typical Power get flat, because only by increase the frequency, the heat that generated by the IC is hard to cooling down.
* Around the year of 2005, single thread performance get flat, and number of cores become to increase exponetially.

> Moore's Law:
>
> <mark style="color:yellow;">The complexity for minimum component costs has increased at a rate of roughly a factor of two per year</mark>. Certainly over the short term this rate can be expected to continue, if not to increase. Over the longer term, the rate of increase is a bit more uncertain, although there is no reason to believe it will not remain nearly constant for at least 10 years.

<figure><img src=".gitbook/assets/image (212).png" alt=""><figcaption></figcaption></figure>

## End of Dennard Scaling

* In 1974, Robert Dennard observed that <mark style="color:yellow;">power density</mark> remained constant for a given area of silicon, while the dimension of the transistor shrank
* In recent years, industry has not been able to reduce supply voltage much, as reducing it further would mean increasing "leakage power" where transistor switches don't fully turn off (more like dimmer switch than on-off switch)&#x20;
* Also, size of transistors and hence capacitance, not shrinking as much as before between transistor generations
  * Need to go to 3D
* Power becomes a growing concern - the "power wall"

## Energy Iron Law

* Performance = Power \* Energy Efficiency (Tasks/Second) (Joules/Second) (Tasks/Joule) • Energy efficiency (e.g., instructions/Joule) is key metric in all computing devices • For power-constrained systems (e.g., 20MW datacenter), need better energy efficiency to get more performance at same power • For energy-constrained systems (e.g., W phone), need better energy efficiency to prolong battery life

<figure><img src=".gitbook/assets/image (214).png" alt=""><figcaption></figcaption></figure>

Pipelining doesn't help latency of single task, it helps throughput of entire workload • Multiple tasks operating simultaneously using different resources • Potential speedup = Number of pipe stages • Time to "fill" pipeline and time to "drain" it reduces speedup: 2.3X v. 4X in this example

<figure><img src=".gitbook/assets/image (215).png" alt=""><figcaption></figcaption></figure>

Pipeline rate limited by slowest pipeline stage Unbalanced lengths of pipe stages reduce speedup

<figure><img src=".gitbook/assets/image (216).png" alt="" width="375"><figcaption></figcaption></figure>

<figure><img src=".gitbook/assets/image (217).png" alt=""><figcaption></figcaption></figure>
